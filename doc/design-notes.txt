2014/10/19 - design notes (updated 2021-01-02)
-------------------------

- static inline functions could be conditionned by #ifdef (eg: dup/unique
  processing, locking, ...)

- EB function names :

  - eb_test{,_ge,_le} : test if the requested key exists
  - eb_find{,_ge,_le} : find the requested key    (= current lookup)
  - eb_pick{,_ge,_le} : find and delete the requested key

- EB trees can be made more space-efficient :

  - optimised for indexing (insert,lookup) : removing node_p/leaf_p
    saves two pointers at the expense of a delete() in O(log(N))

  - compact key storage : removing bit/depth makes all operations
    happen on the XOR of the keys. This is efficient when keys are the
    branches addresses, but for all other situations it means one
    indirect access to retrieve the key. Ordered dups are not possible
    anymore, at best the node's address can be used as a sorting key
    between them. This is acceptable for indexing since it will also
    match the arrival order. It's also acceptable for memory area
    lookups where there cannot be any dups.

- compact+indexing are useful for memory area indexing. Can be open-coded in
  a memory manager to have another operation : eb_fuse{_lt,_gt} : make the
  lookup function aware of the contents of the node. Typically the node is
  indexed by its own position and contains a size. The eb_fuse_lt() function
  will look up the largest key strictly smaller than the value passed, and
  will verify that this key + its size exactly match the value passed. If so,
  then the two are merged into a larger entry (sizes add up) and the resulting
  key is returned. eb_fuse_gt() does the opposite, it looks up the key larger
  than value+its size, and if found, then the new key is inserted with the
  total size and the previous one is removed. There's the case where inserting
  one key results in removing 2 (the previous and the next one), maybe we should
  consider 3 fuse operations instead :

      - fuse_before
      - fuse_after
      - fuse_middle

  It seems this should be open-coded though.

- Deleting a node in optimised-for-indexing mode is difficult :

   - ... but is needed (purge, timeout, etc...)
   - the key needs to be looked up first in the tree
   - then in case the tree supports dups, the proper node needs to be found
     based on the dup-indexing method (eg: use the pointer as a second key).


==> EB trees can be tailored for various usages :

    - very fast and fair insertion/removal (eg: timers, priority queues, ...),
      or complex operations such as prefix lookups
      => full EB tree

    - no/unfair dups processing, slower indirect lookup but more compact
      storage without no bit/depth. Useful for fast memory area indexing
      (pointers are keys).
      => compact EB tree, saves 32-bit per node.

    - indexing words (eg: log processing), slow removal :
      => indexing EB tree (without upper pointers).

    - indexing words/pointers with very low overhead, slow removal, no/unfair
      dups (flat log indexing, low-overhead memory management)
      => CB tree (compact+indexing)

Alignment:
----------

In environments where strict double-word alignment is guaranteed on structures,
it is possible to simplify the pointer typing by making pointers target their
reciprocal pointer on the other node instead of being artificially typed. This
means that a node's header would look like this :

   offset

   0x0000 left branch
   0x0008 right branch
   0x0010 node's parent
   0x0018 leaf's parent
   0x0020 ...

A branch will point to either the node's parent pointer or the leaf's parent
pointer. The distinction will be done on (long)pointer & 8 (or &4 on 32-bit
machines). Conversely, a node_p or leaf_p will point to the left branch pointer
or to the right branch pointer depending where the node (or leaf) is attached.
This adds a few properties to the system, one of them being that **p == p for
any pointer in the tree. It could even make sense that a detached node points
to itself to guarantee permanent pointer validity (e.g. empty root.

Avoiding tests before fetching helps the processor speculatively prefetch the
next memory location without having to rely on branch prediction that does not
works in trees.


Compact trees (cbtree)
----------------------

Compact trees currently rely on XORing the key only to organize the descent,
which prevents from storing duplicates (unless a secondary key such as the node
pointer is used, which is only fine in linear addressing schemes like database
indexes given that it otherwise breaks insertion ordering).

However it is also possible to deal with a duplicate tree using pointer typing,
resulting in insertion in O(log(N)+log^2(M)) and removal in O(M+log(N)) where N
is the number of unique keys in the tree and M the highest number of duplicates
for a given key. This remains perfectly reasonable for storing configuration
keys that do not change often, need to support rare duplicates, but require
efficient storage and fast lookups.

The principle remains, like in regular ebtrees, to store a node pointer
verbatim and a leaf pointer with bit 0 set. On insertion, when a duplicate is
detected, a subtree needs to be created (or completed). For this, the principle
is to insert a node on the rightmost branch at the deepest level which will not
make that branch longer than the closest left one. The algorithm is thus :

  - descend along nodes as long as values differ between sides
  - descend along duplicates on the right as long as both sides are nodes.
  - if left side is a node and right side a leaf, insert on the right link,
    between the node and the leaf.
  - otherwise, either left side is a leaf or both sides are leaves. The left
    branch's length is known (1). Let's go up and measure the depth of the
    upper left branch (we're on the right). As soon as the left branch's
    depth is strictly larger than the current one, insert the new node on the
    right branch, with the subtree on the left and the new leaf on the right.

This is where pointer typing becomes mandatory, as the keys cannot be used
anymore to distinguish between a node and a leaf. What is uncertain at this
point is whether it's preferable to use typed pointers only in the duplicate
subtree or everywhere: a duplicate subtree is trivially detected by having its
two sides point to the same value, but it also means that the pointer must
already be checked in case the node is directly attached to a leaf.

The removal in duplicates (without secondary key) will require looking up the
subtree head for the key, and searching the node through all the duplicates.
With few duplicates it is not an issue. But it could become one when dealing
with hundreds or thousands of duplicates, like when indexing logs. In this
case relying on linear addressing and a subkey would be preferred.


Special pointer values
----------------------

In every node, there are a number of special values that can be used by
pointers:

  - node_p: 0
  - node_p: &node .. &node + sizeof(node) - 1
  - leaf_p: 0
  - leaf_p: &node .. &node + sizeof(node) - 1 with the exception of branch
            addresses
  - leaf_p == node_p
  - branches: 0
  - branches: &node .. &node + sizeof(node) - 1 except valid values for a leaf
  - branches: l == r
  - all: lower bits set depending on the environment

Thus special cases like a pointer pointing to itself or directly to the node's
own key, or to the other of the same type, could be exploited to mention
certain situations (deleted or locked node for example). For example, creating
an infinite loop can be convenient for locking so that concurrent readers loop
over the same pointer instead of having to explicitly test it.


Locking
-------

Tests have shown that generic locking at the tree level is impractical. Instead
what is needed is to provide low-level subfunctions to perform the tree descent
and the insertion/removal operations so that the user can add their own locks
as desired. This will allow to make use of spinlocks, R/W locks, or upgradable
locks for the complete operation, at low cost. It will also avoid taking too
strong a lock if an operation needs to fail (e.g. failed insert, failed pick).
It would also allow the user to choose the best strategy for upgradable locks,
such as read-lock + tentative upgrade + retry vs seek-lock + upgrade. For a
cache, the read+tentative+retry is often more effective as it remains a shared
lock for every hit, and the missed upgrades can remain rare enough when the
cache hit ration is high.

At first glance, some basic operations should provide such features:
  - insertion: descend the tree while memorizing the parent and grandparent's
    attach point, giving them back to the caller, along with information about
    success (continue or give up)
  - insertion: special case for duplicate insertion (does not use the key, only
    the tree's structure)
  - removal: grand parent and parent are both needed. Maybe a bit more.
  - probaby a special case of removal in dup tree so that the caller does not
    need to implement it when not needed.
  - pick: lookup based on the strategy (exact, prefix, longest, ge, le) while
    retaining parent and grand parent.

Lookup doesn't seem to require anything special, given that the caller will
probably lock for reads around the whole operation. Same for the existence
test.
